{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "Reddit is a social media forum on the internet.  Many \"subreddits\", forums dedicated to particular topics, make up the entirety of Reddit.  Users can pick and choose which subreddits will comprise their own Reddit, making them unique to each user.\n",
    "\n",
    "The Stanford Network Analysis Project (SNAP) has [two datasets of Reddit's Hyperlink network](http://snap.stanford.edu/data/soc-RedditHyperlinks.html).  SNAP's datasets are concerned with Reddit posts that link to other subreddits.  Each entry has a source subreddit and a target subreddit along with a sentiment score (-1 for negative, and 1 for neutral/positive).  This is because some subreddits are created in response to other subreddits.  Utilizing the centrality measures, we can then determine which subreddits are most prone to being attacked, which do the most attacking, and the inverse.  Essentially, we can see which subreddits are popular enough to drive conversation around the rest of Reddit.\n",
    "\n",
    "First, we'll load the data.\n",
    "\n",
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "title = pd.read_csv('soc-RedditHyperlinks-title.tsv', sep = '\\t')\n",
    "body = pd.read_csv('soc-RedditHyperlinks-body.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though a more indepth analysis can be done utilizing the `PROPERTIES` variable--allowing one to determine the number of characters, or average word length, or readability index--we will be mostly focusing on the sentiment between the `SOURCE_SUBREDDIT` and `TARGET_SUBREDDIT`.  For that, we'll drop the columns we won't be using, and merge the two dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rddtgaming</td>\n",
       "      <td>rddtrust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xboxone</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps4</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>leangains</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>lifeprotips</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SOURCE_SUBREDDIT TARGET_SUBREDDIT  LINK_SENTIMENT\n",
       "0         rddtgaming         rddtrust               1\n",
       "1            xboxone    battlefield_4               1\n",
       "2                ps4    battlefield_4               1\n",
       "3  fitnesscirclejerk        leangains               1\n",
       "4  fitnesscirclejerk      lifeprotips               1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = title.drop(['POST_ID', 'TIMESTAMP', 'PROPERTIES'], axis = 1)\n",
    "body = body.drop(['POST_ID', 'TIMESTAMP', 'PROPERTIES'], axis = 1)\n",
    "final = pd.concat([title, body])\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the dataframe between the `LINK_SENTIMENT` so that we can run centrality on those that have a positive/neutral connection, and those that have a negative connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = final[final['LINK_SENTIMENT'] == 1]\n",
    "bad = final[final['LINK_SENTIMENT'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive/Neutral Subreddit Centrality\n",
      "                   Score\n",
      "askreddit       0.079783\n",
      "iama            0.068264\n",
      "pics            0.049445\n",
      "bestof          0.047594\n",
      "funny           0.046562\n",
      "subredditdrama  0.045666\n",
      "todayilearned   0.039914\n",
      "videos          0.039429\n",
      "titlegore       0.037638\n",
      "gaming          0.031932\n",
      "\n",
      "Negative Subreddit Centrality\n",
      "                   Score\n",
      "subredditdrama  0.160176\n",
      "bestof          0.096371\n",
      "askreddit       0.095210\n",
      "drama           0.073832\n",
      "funny           0.045161\n",
      "todayilearned   0.042923\n",
      "pics            0.041598\n",
      "worldnews       0.041183\n",
      "videos          0.039277\n",
      "the_donald      0.037869\n"
     ]
    }
   ],
   "source": [
    "GG = nx.from_pandas_edgelist(good, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT')\n",
    "pCent = nx.degree_centrality(GG)\n",
    "pc = pd.DataFrame.from_dict(pCent, orient = 'index', columns = ['Score'])\n",
    "pc = pc.sort_values(by = 'Score', ascending = False)\n",
    "\n",
    "NG = nx.from_pandas_edgelist(bad, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT')\n",
    "nCent = nx.degree_centrality(NG)\n",
    "nc = pd.DataFrame.from_dict(nCent, orient = 'index', columns = ['Score'])\n",
    "nc = nc.sort_values(by = 'Score', ascending = False)\n",
    "\n",
    "print(\"Positive/Neutral Subreddit Centrality\")\n",
    "print(pc.head(10))\n",
    "print(\"\")\n",
    "print(\"Negative Subreddit Centrality\")\n",
    "print(nc.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of overlap between both categories, at least within the top 10.  Seven subreddits score high in both, although `subredditdrama` scores the highest with `0.16`.  Given the name, however, it's not surprising that it should be the recipient of a lot of negative attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive/Neutral Subreddit Eigenvector Centrality\n",
      "                   Score\n",
      "askreddit       0.156323\n",
      "iama            0.140738\n",
      "bestof          0.139014\n",
      "subredditdrama  0.136979\n",
      "pics            0.125949\n",
      "funny           0.124222\n",
      "todayilearned   0.122006\n",
      "videos          0.116535\n",
      "titlegore       0.111079\n",
      "gaming          0.092022\n",
      "\n",
      "Negative Subreddit Eigenvector Centrality\n",
      "                   Score\n",
      "subredditdrama  0.243658\n",
      "bestof          0.189298\n",
      "askreddit       0.177516\n",
      "drama           0.173328\n",
      "todayilearned   0.127277\n",
      "shitredditsays  0.116804\n",
      "circlebroke2    0.116738\n",
      "the_donald      0.115641\n",
      "worldnews       0.115317\n",
      "funny           0.115199\n"
     ]
    }
   ],
   "source": [
    "peCent = nx.eigenvector_centrality(GG)\n",
    "pe = pd.DataFrame.from_dict(peCent, orient = 'index', columns = ['Score'])\n",
    "pe = pe.sort_values(by = 'Score', ascending = False)\n",
    "\n",
    "neCent = nx.eigenvector_centrality(NG)\n",
    "ne = pd.DataFrame.from_dict(neCent, orient = 'index', columns = ['Score'])\n",
    "ne = ne.sort_values(by = 'Score', ascending = False)\n",
    "\n",
    "print(\"Positive/Neutral Subreddit Eigenvector Centrality\")\n",
    "print(pe.head(10))\n",
    "print(\"\")\n",
    "print(\"Negative Subreddit Eigenvector Centrality\")\n",
    "print(ne.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvector centralities share less subreddits than the regular centralities.  Only five subreddits are shared between the top 10.  Interestingly, however, the top ten for positive/neutral is nearly identical for both.  Only the ordering is different.  For the negative lists, 8 of the top ten are shared.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We can see that the popular subreddits (`askreddit`, `bestof`, `subredditdrama`, `pics`, `funny`, `todayilearned`, `videos`) attract both positive and negative buzz throughout Reddit itself.  This is a good thing, as Reddit comes with a predefined list of subreddits a new user is automatically subscribed to.  Utilizing networks like this, they could potentially make that list much more dynamic.  In addition to subreddits that are simply popular, a new user could also ask to be subscribed to popular subreddits that are not controversial--that is subreddits that rank high on the positive/neutral, but lower in the negative--or vice versa.\n",
    "\n",
    "Obviously moderators of each subreddit could utilize these networks to see where a lot of negative linkage is coming from, because this occasionally results in invasions, where the users of one subreddit will swarm another en masse to downvote the users/posts of the other subreddit.  Indeed, it would be interesting to see how many of these links were calling for just such an action.  The moderators could then be provided with tools to better protect themselves, so that the flow of their daily usage is not interrupted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
